{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fa6c6438e20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from custom_models import cnn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations to loop through\n",
    "minimal_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "basic_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "auto_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Set with Real/Synthetic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSyntheticTrain(train_directory, synthetic_train_directory, train_percentage, synthetic_percentage):\n",
    "\n",
    "    # Remove any existing images in directory\n",
    "    try:\n",
    "        shutil.rmtree(synthetic_train_directory)\n",
    "    except:\n",
    "        print(\"directory does not exist\")\n",
    "\n",
    "    # Loop through subfolders, generate synthetic images\n",
    "    subfolders = [f for f in os.listdir(train_directory)]\n",
    "\n",
    "    for s in subfolders:\n",
    "        # for each subfolder in the train directory, make the same in the synthetic train directory\n",
    "        os.makedirs(f\"{synthetic_train_directory}/{s}\", exist_ok=True)\n",
    "        \n",
    "        # get a random sample from each subfolder\n",
    "        subfolder_path = f\"{train_directory}/{s}\"\n",
    "        files = os.listdir(subfolder_path)\n",
    "        sample_files = random.sample(files, round(len(files)*train_percentage))\n",
    "        \n",
    "        # create synthetic sample based on sampled original images\n",
    "        synthetic_subfolder_path = subfolder_path.replace('train','synthetic')\n",
    "        synthetic_files = [f for f in os.listdir(synthetic_subfolder_path) if int(f.replace('.png','').split('_')[1]) in [int(f.replace('.png','').split('_')[1]) for f in sample_files]]\n",
    "        synthetic_sample_files = random.sample(synthetic_files, round(len(files)*synthetic_percentage))\n",
    "        \n",
    "        # Move sample files to synthetic directory\n",
    "        for f in sample_files:\n",
    "            \n",
    "            image_path = f\"{subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])\n",
    "\n",
    "        # Move synthetic sample files to synthetic directory\n",
    "        for f in synthetic_sample_files:\n",
    "\n",
    "            image_path = f\"{synthetic_subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, data_sets, data_transforms):\n",
    "    \n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            data_transforms[x]\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=4,\n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        x: len(image_datasets[x]) \n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    class_names = image_datasets['synthetic_train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return image_datasets, dataloaders, dataset_sizes, class_names, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "        best_test_loss = float('inf')\n",
    "        patience = 2  # Number of epochs to wait for improvement before stopping\n",
    "        test_losses = []\n",
    "        train_losses = []\n",
    "        test_acc = []\n",
    "        train_acc = []\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['synthetic_train', 'test']:\n",
    "                if phase == 'synthetic_train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'synthetic_train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'synthetic_train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double().item() / dataset_sizes[phase]\n",
    "\n",
    "                if phase =='synthetic_train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_acc.append(epoch_acc)\n",
    "                else:\n",
    "                    test_losses.append(epoch_loss)\n",
    "                    test_acc.append(epoch_acc)\n",
    "                    \n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_loss <= best_test_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "                    patience_counter = 0  # Reset counter\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                elif phase == 'test' and epoch_loss > best_test_loss:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                # Early stopping check\n",
    "                #if patience_counter >= patience:\n",
    "                #    print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                #    break\n",
    "\n",
    "        # store results in dataframe\n",
    "        dat = {\n",
    "            \"epoch\": range(len(test_losses)),\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_accuracies\": test_acc,\n",
    "            \"train_accuracies\": train_acc\n",
    "        }\n",
    "\n",
    "        result = pd.DataFrame(data=dat)\n",
    "        print()\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Loss: {best_test_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return result, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through different training scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0536 Acc: 0.4949\n",
      "test Loss: 1.0038 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0164 Acc: 0.5018\n",
      "test Loss: 0.9434 Acc: 0.5516\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9853 Acc: 0.5211\n",
      "test Loss: 0.8737 Acc: 0.5586\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9379 Acc: 0.5389\n",
      "test Loss: 0.8622 Acc: 0.5664\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8942 Acc: 0.5611\n",
      "test Loss: 0.7465 Acc: 0.6461\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8484 Acc: 0.5957\n",
      "test Loss: 0.6493 Acc: 0.7242\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7907 Acc: 0.6357\n",
      "test Loss: 0.5723 Acc: 0.7719\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7286 Acc: 0.6676\n",
      "test Loss: 0.5117 Acc: 0.8039\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6766 Acc: 0.6941\n",
      "test Loss: 0.4718 Acc: 0.8492\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6394 Acc: 0.7119\n",
      "test Loss: 0.4258 Acc: 0.8523\n",
      "\n",
      "Training complete in 3m 48s\n",
      "Best test Loss: 0.425759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0522 Acc: 0.4998\n",
      "test Loss: 0.9651 Acc: 0.5750\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0056 Acc: 0.5213\n",
      "test Loss: 0.9256 Acc: 0.5719\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9783 Acc: 0.5254\n",
      "test Loss: 0.8077 Acc: 0.6344\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9240 Acc: 0.5633\n",
      "test Loss: 0.6591 Acc: 0.7086\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8562 Acc: 0.5998\n",
      "test Loss: 0.5593 Acc: 0.7789\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7713 Acc: 0.6402\n",
      "test Loss: 0.4880 Acc: 0.8070\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7135 Acc: 0.6723\n",
      "test Loss: 0.4675 Acc: 0.8391\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6687 Acc: 0.7045\n",
      "test Loss: 0.3445 Acc: 0.8797\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6149 Acc: 0.7291\n",
      "test Loss: 0.3494 Acc: 0.8852\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5538 Acc: 0.7623\n",
      "test Loss: 0.2670 Acc: 0.9062\n",
      "\n",
      "Training complete in 3m 38s\n",
      "Best test Loss: 0.267002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0568 Acc: 0.4906\n",
      "test Loss: 0.9704 Acc: 0.5258\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0114 Acc: 0.5143\n",
      "test Loss: 0.9057 Acc: 0.5563\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9619 Acc: 0.5285\n",
      "test Loss: 0.8638 Acc: 0.5625\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9267 Acc: 0.5479\n",
      "test Loss: 0.7685 Acc: 0.6609\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8745 Acc: 0.5824\n",
      "test Loss: 0.6348 Acc: 0.7195\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8087 Acc: 0.6201\n",
      "test Loss: 0.5271 Acc: 0.7773\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7420 Acc: 0.6629\n",
      "test Loss: 0.4851 Acc: 0.8117\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6755 Acc: 0.6979\n",
      "test Loss: 0.3293 Acc: 0.8672\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6462 Acc: 0.7125\n",
      "test Loss: 0.3260 Acc: 0.8820\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5961 Acc: 0.7279\n",
      "test Loss: 0.4459 Acc: 0.8344\n",
      "\n",
      "Training complete in 3m 39s\n",
      "Best test Loss: 0.325966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0552 Acc: 0.4857\n",
      "test Loss: 0.9866 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0175 Acc: 0.5041\n",
      "test Loss: 0.9432 Acc: 0.5203\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9793 Acc: 0.5291\n",
      "test Loss: 0.8425 Acc: 0.6008\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9410 Acc: 0.5537\n",
      "test Loss: 0.7773 Acc: 0.6305\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8774 Acc: 0.5930\n",
      "test Loss: 0.6309 Acc: 0.7297\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8249 Acc: 0.6234\n",
      "test Loss: 0.5490 Acc: 0.7648\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7638 Acc: 0.6566\n",
      "test Loss: 0.4831 Acc: 0.8133\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7178 Acc: 0.6748\n",
      "test Loss: 0.4112 Acc: 0.8484\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6659 Acc: 0.6965\n",
      "test Loss: 0.4592 Acc: 0.8297\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6074 Acc: 0.7301\n",
      "test Loss: 0.3770 Acc: 0.8586\n",
      "\n",
      "Training complete in 3m 48s\n",
      "Best test Loss: 0.377009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0482 Acc: 0.4896\n",
      "test Loss: 0.9108 Acc: 0.5555\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9948 Acc: 0.5199\n",
      "test Loss: 1.0238 Acc: 0.5430\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9834 Acc: 0.5221\n",
      "test Loss: 0.8306 Acc: 0.5844\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9215 Acc: 0.5566\n",
      "test Loss: 0.7313 Acc: 0.6594\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8734 Acc: 0.5885\n",
      "test Loss: 0.6101 Acc: 0.7398\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8107 Acc: 0.6199\n",
      "test Loss: 0.5220 Acc: 0.7859\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7499 Acc: 0.6605\n",
      "test Loss: 0.5575 Acc: 0.7805\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6911 Acc: 0.6865\n",
      "test Loss: 0.4864 Acc: 0.8492\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6626 Acc: 0.6984\n",
      "test Loss: 0.5717 Acc: 0.8258\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6169 Acc: 0.7246\n",
      "test Loss: 0.4408 Acc: 0.8609\n",
      "\n",
      "Training complete in 4m 5s\n",
      "Best test Loss: 0.440784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0634 Acc: 0.4945\n",
      "test Loss: 0.9984 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0124 Acc: 0.5064\n",
      "test Loss: 0.9099 Acc: 0.5188\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9837 Acc: 0.5102\n",
      "test Loss: 0.8480 Acc: 0.5687\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9511 Acc: 0.5303\n",
      "test Loss: 0.8387 Acc: 0.6039\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9085 Acc: 0.5506\n",
      "test Loss: 0.7596 Acc: 0.6742\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8594 Acc: 0.5873\n",
      "test Loss: 0.6178 Acc: 0.7492\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7955 Acc: 0.6273\n",
      "test Loss: 0.6266 Acc: 0.7703\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7488 Acc: 0.6553\n",
      "test Loss: 0.5027 Acc: 0.8266\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6832 Acc: 0.6904\n",
      "test Loss: 0.6388 Acc: 0.7695\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6500 Acc: 0.7045\n",
      "test Loss: 0.4528 Acc: 0.8672\n",
      "\n",
      "Training complete in 3m 58s\n",
      "Best test Loss: 0.452775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0680 Acc: 0.4865\n",
      "test Loss: 1.0452 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0257 Acc: 0.5018\n",
      "test Loss: 0.9273 Acc: 0.5586\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0043 Acc: 0.5164\n",
      "test Loss: 0.9064 Acc: 0.5555\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9747 Acc: 0.5295\n",
      "test Loss: 0.8671 Acc: 0.5758\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9346 Acc: 0.5535\n",
      "test Loss: 0.7373 Acc: 0.6758\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8958 Acc: 0.5805\n",
      "test Loss: 0.6606 Acc: 0.7195\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8321 Acc: 0.6146\n",
      "test Loss: 0.5362 Acc: 0.7797\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7787 Acc: 0.6350\n",
      "test Loss: 0.5604 Acc: 0.8016\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7097 Acc: 0.6721\n",
      "test Loss: 0.4708 Acc: 0.8422\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6656 Acc: 0.6881\n",
      "test Loss: 0.4217 Acc: 0.8453\n",
      "\n",
      "Training complete in 3m 43s\n",
      "Best test Loss: 0.421739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0573 Acc: 0.4965\n",
      "test Loss: 1.0439 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0331 Acc: 0.5018\n",
      "test Loss: 0.9195 Acc: 0.5453\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0054 Acc: 0.5207\n",
      "test Loss: 0.8544 Acc: 0.5711\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9782 Acc: 0.5271\n",
      "test Loss: 0.8105 Acc: 0.6195\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9424 Acc: 0.5496\n",
      "test Loss: 0.9063 Acc: 0.6281\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9005 Acc: 0.5646\n",
      "test Loss: 0.6720 Acc: 0.6992\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8428 Acc: 0.5939\n",
      "test Loss: 0.6016 Acc: 0.7438\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7921 Acc: 0.6193\n",
      "test Loss: 0.5244 Acc: 0.8016\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7666 Acc: 0.6404\n",
      "test Loss: 0.7931 Acc: 0.7094\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7283 Acc: 0.6682\n",
      "test Loss: 0.3817 Acc: 0.8547\n",
      "\n",
      "Training complete in 3m 50s\n",
      "Best test Loss: 0.381680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0576 Acc: 0.4963\n",
      "test Loss: 1.0286 Acc: 0.4953\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0215 Acc: 0.5027\n",
      "test Loss: 0.9691 Acc: 0.5359\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9940 Acc: 0.5186\n",
      "test Loss: 0.9591 Acc: 0.5555\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9502 Acc: 0.5518\n",
      "test Loss: 0.8278 Acc: 0.6453\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9097 Acc: 0.5732\n",
      "test Loss: 0.7530 Acc: 0.6758\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8347 Acc: 0.6070\n",
      "test Loss: 0.8020 Acc: 0.6703\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7771 Acc: 0.6480\n",
      "test Loss: 0.4899 Acc: 0.8109\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7315 Acc: 0.6652\n",
      "test Loss: 0.3783 Acc: 0.8664\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6814 Acc: 0.6945\n",
      "test Loss: 0.6786 Acc: 0.7758\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6256 Acc: 0.7207\n",
      "test Loss: 0.3357 Acc: 0.8852\n",
      "\n",
      "Training complete in 3m 41s\n",
      "Best test Loss: 0.335734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0540 Acc: 0.4986\n",
      "test Loss: 0.9586 Acc: 0.5078\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0096 Acc: 0.5145\n",
      "test Loss: 0.9163 Acc: 0.5461\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9827 Acc: 0.5260\n",
      "test Loss: 0.8665 Acc: 0.5727\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9583 Acc: 0.5389\n",
      "test Loss: 0.8419 Acc: 0.6211\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9031 Acc: 0.5686\n",
      "test Loss: 0.6623 Acc: 0.6875\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8453 Acc: 0.6057\n",
      "test Loss: 0.5142 Acc: 0.7797\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7788 Acc: 0.6371\n",
      "test Loss: 0.4487 Acc: 0.8086\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7556 Acc: 0.6414\n",
      "test Loss: 0.3631 Acc: 0.8539\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7093 Acc: 0.6689\n",
      "test Loss: 0.3384 Acc: 0.8625\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6806 Acc: 0.6824\n",
      "test Loss: 0.2919 Acc: 0.8898\n",
      "\n",
      "Training complete in 3m 44s\n",
      "Best test Loss: 0.291883\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "num_sims = 10\n",
    "train_percs = [0.8]#[1.0, 0.8, 0.8, 0.6, 0.6, 0.4, 0.4]\n",
    "synth_percs = [0.0]#[0.0, 0.2, 0.0, 0.4, 0.0, 0.6, 0.0]\n",
    "transforms = {\n",
    "    'minimal': minimal_transforms,\n",
    "    'basic': basic_transforms,\n",
    "    'auto': auto_transforms\n",
    "}\n",
    "\n",
    "for train_percentage, synthetic_percentage in zip(train_percs, synth_percs):\n",
    "    for active_transform in transforms.keys():\n",
    "        df_all_results = pd.DataFrame()\n",
    "        for n in range(num_sims):\n",
    "    \n",
    "            # make the synthetic training dataset\n",
    "            makeSyntheticTrain(\n",
    "                train_directory='../data/alzheimer_mri/train',\n",
    "                synthetic_train_directory='../data/alzheimer_mri/synthetic_train', \n",
    "                train_percentage=train_percentage, \n",
    "                synthetic_percentage=synthetic_percentage\n",
    "            )\n",
    "\n",
    "            # get and load datasets\n",
    "            data_dir = '../data/alzheimer_mri'\n",
    "            data_sets = ['synthetic_train','test']\n",
    "            image_datasets, dataloaders, dataset_sizes, class_names, device = get_data(\n",
    "                data_dir=data_dir, \n",
    "                data_sets=data_sets, \n",
    "                data_transforms=transforms.get(active_transform)\n",
    "            )\n",
    "\n",
    "            # instantiate model\n",
    "            model = cnn.CNN(in_channels=1, num_classes=4)\n",
    "\n",
    "            # Set the size of each output sample to nn.Linear(num_ftrs, len(class_names))\n",
    "            #num_ftrs = 4 #model.fc.in_features\n",
    "            #model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "            model = model.to(device)\n",
    "\n",
    "            # train the model\n",
    "            df_results,_ = model = train_model(\n",
    "                model=model, \n",
    "                criterion = nn.CrossEntropyLoss(),\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001), \n",
    "                dataloaders=dataloaders,\n",
    "                dataset_sizes=dataset_sizes,\n",
    "                num_epochs=num_epochs\n",
    "            )\n",
    "\n",
    "            df_results['train_percentage'] = train_percentage\n",
    "            df_results['synth_percentage'] = synthetic_percentage\n",
    "            df_results['transform'] = active_transform\n",
    "            df_results['sim_num'] = n\n",
    "            df_results['category'] = df_results.apply(lambda row: row['transform']+'_'+str(row['train_percentage'])+'_'+str(row['synth_percentage']), axis=1)\n",
    "            df_all_results = pd.concat([df_all_results, df_results],ignore_index=True)\n",
    "        df_all_results.to_csv('../results/results_cnn_'+active_transform+'_'+str(train_percentage)+'_'+str(synthetic_percentage)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
