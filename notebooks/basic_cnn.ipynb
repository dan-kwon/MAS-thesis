{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fa6c6438e20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from custom_models import cnn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations to loop through\n",
    "minimal_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "basic_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "auto_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Set with Real/Synthetic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSyntheticTrain(train_directory, synthetic_train_directory, train_percentage, synthetic_percentage):\n",
    "\n",
    "    # Remove any existing images in directory\n",
    "    try:\n",
    "        shutil.rmtree(synthetic_train_directory)\n",
    "    except:\n",
    "        print(\"directory does not exist\")\n",
    "\n",
    "    # Loop through subfolders, generate synthetic images\n",
    "    subfolders = [f for f in os.listdir(train_directory)]\n",
    "\n",
    "    for s in subfolders:\n",
    "        # for each subfolder in the train directory, make the same in the synthetic train directory\n",
    "        os.makedirs(f\"{synthetic_train_directory}/{s}\", exist_ok=True)\n",
    "        \n",
    "        # get a random sample from each subfolder\n",
    "        subfolder_path = f\"{train_directory}/{s}\"\n",
    "        files = os.listdir(subfolder_path)\n",
    "        sample_files = random.sample(files, round(len(files)*train_percentage))\n",
    "        \n",
    "        # create synthetic sample based on sampled original images\n",
    "        synthetic_subfolder_path = subfolder_path.replace('train','synthetic')\n",
    "        synthetic_files = [f for f in os.listdir(synthetic_subfolder_path) if int(f.replace('.png','').split('_')[1]) in [int(f.replace('.png','').split('_')[1]) for f in sample_files]]\n",
    "        synthetic_sample_files = random.sample(synthetic_files, round(len(files)*synthetic_percentage))\n",
    "        \n",
    "        # Move sample files to synthetic directory\n",
    "        for f in sample_files:\n",
    "            \n",
    "            image_path = f\"{subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])\n",
    "\n",
    "        # Move synthetic sample files to synthetic directory\n",
    "        for f in synthetic_sample_files:\n",
    "\n",
    "            image_path = f\"{synthetic_subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, data_sets, data_transforms):\n",
    "    \n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            data_transforms[x]\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=4,\n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        x: len(image_datasets[x]) \n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    class_names = image_datasets['synthetic_train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return image_datasets, dataloaders, dataset_sizes, class_names, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "        best_test_loss = float('inf')\n",
    "        patience = 2  # Number of epochs to wait for improvement before stopping\n",
    "        test_losses = []\n",
    "        train_losses = []\n",
    "        test_acc = []\n",
    "        train_acc = []\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['synthetic_train', 'test']:\n",
    "                if phase == 'synthetic_train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'synthetic_train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'synthetic_train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double().item() / dataset_sizes[phase]\n",
    "\n",
    "                if phase =='synthetic_train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_acc.append(epoch_acc)\n",
    "                else:\n",
    "                    test_losses.append(epoch_loss)\n",
    "                    test_acc.append(epoch_acc)\n",
    "                    \n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_loss <= best_test_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "                    patience_counter = 0  # Reset counter\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                elif phase == 'test' and epoch_loss > best_test_loss:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                # Early stopping check\n",
    "                #if patience_counter >= patience:\n",
    "                #    print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                #    break\n",
    "\n",
    "        # store results in dataframe\n",
    "        dat = {\n",
    "            \"epoch\": range(len(test_losses)),\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_accuracies\": test_acc,\n",
    "            \"train_accuracies\": train_acc\n",
    "        }\n",
    "\n",
    "        result = pd.DataFrame(data=dat)\n",
    "        print()\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Loss: {best_test_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return result, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through different training scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_sims = 10\n",
    "train_percs = [0.6, 0.6, 0.4, 0.4]\n",
    "synth_percs = [0.4, 0.0, 0.6, 0.0]\n",
    "transforms = {\n",
    "    'minimal': minimal_transforms,\n",
    "    'basic': basic_transforms,\n",
    "    'auto': auto_transforms\n",
    "}\n",
    "\n",
    "for train_percentage, synthetic_percentage in zip(train_percs, synth_percs):\n",
    "    for active_transform in transforms.keys():\n",
    "        df_all_results = pd.DataFrame()\n",
    "        for n in range(num_sims):\n",
    "    \n",
    "            # make the synthetic training dataset\n",
    "            makeSyntheticTrain(\n",
    "                train_directory='../data/alzheimer_mri/train',\n",
    "                synthetic_train_directory='../data/alzheimer_mri/synthetic_train', \n",
    "                train_percentage=train_percentage, \n",
    "                synthetic_percentage=synthetic_percentage\n",
    "            )\n",
    "\n",
    "            # get and load datasets\n",
    "            data_dir = '../data/alzheimer_mri'\n",
    "            data_sets = ['synthetic_train','test']\n",
    "            image_datasets, dataloaders, dataset_sizes, class_names, device = get_data(\n",
    "                data_dir=data_dir, \n",
    "                data_sets=data_sets, \n",
    "                data_transforms=transforms.get(active_transform)\n",
    "            )\n",
    "\n",
    "            # instantiate model\n",
    "            model = cnn.CNN(in_channels=1, num_classes=4)\n",
    "\n",
    "            # Set the size of each output sample to nn.Linear(num_ftrs, len(class_names))\n",
    "            #num_ftrs = 4 #model.fc.in_features\n",
    "            #model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "            model = model.to(device)\n",
    "\n",
    "            # train the model\n",
    "            df_results,_ = model = train_model(\n",
    "                model=model, \n",
    "                criterion = nn.CrossEntropyLoss(),\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001), \n",
    "                dataloaders=dataloaders,\n",
    "                dataset_sizes=dataset_sizes,\n",
    "                num_epochs=num_epochs\n",
    "            )\n",
    "\n",
    "            df_results['train_percentage'] = train_percentage\n",
    "            df_results['synth_percentage'] = synthetic_percentage\n",
    "            df_results['transform'] = active_transform\n",
    "            df_results['sim_num'] = n\n",
    "            df_results['category'] = df_results.apply(lambda row: row['transform']+'_'+str(row['train_percentage'])+'_'+str(row['synth_percentage']), axis=1)\n",
    "            df_all_results = pd.concat([df_all_results, df_results],ignore_index=True)\n",
    "        df_all_results.to_csv('../results/results_cnn_'+active_transform+'_'+str(train_percentage)+'_'+str(synthetic_percentage)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
