{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fa6c6438e20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from custom_models import cnn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations to loop through\n",
    "minimal_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "basic_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "auto_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize([0.5, ],[0.5, ]),\n",
    "        v2.Resize((128, 128))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Set with Real/Synthetic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSyntheticTrain(train_directory, synthetic_train_directory, train_percentage, synthetic_percentage):\n",
    "\n",
    "    # Remove any existing images in directory\n",
    "    try:\n",
    "        shutil.rmtree(synthetic_train_directory)\n",
    "    except:\n",
    "        print(\"directory does not exist\")\n",
    "\n",
    "    # Loop through subfolders, generate synthetic images\n",
    "    subfolders = [f for f in os.listdir(train_directory)]\n",
    "\n",
    "    for s in subfolders:\n",
    "        # for each subfolder in the train directory, make the same in the synthetic train directory\n",
    "        os.makedirs(f\"{synthetic_train_directory}/{s}\", exist_ok=True)\n",
    "        \n",
    "        # get a random sample from each subfolder\n",
    "        subfolder_path = f\"{train_directory}/{s}\"\n",
    "        files = os.listdir(subfolder_path)\n",
    "        sample_files = random.sample(files, round(len(files)*train_percentage))\n",
    "        \n",
    "        # create synthetic sample based on sampled original images\n",
    "        synthetic_subfolder_path = subfolder_path.replace('train','synthetic')\n",
    "        synthetic_files = [f for f in os.listdir(synthetic_subfolder_path) if int(f.replace('.png','').split('_')[1]) in [int(f.replace('.png','').split('_')[1]) for f in sample_files]]\n",
    "        synthetic_sample_files = random.sample(synthetic_files, round(len(files)*synthetic_percentage))\n",
    "        \n",
    "        # Move sample files to synthetic directory\n",
    "        for f in sample_files:\n",
    "            \n",
    "            image_path = f\"{subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])\n",
    "\n",
    "        # Move synthetic sample files to synthetic directory\n",
    "        for f in synthetic_sample_files:\n",
    "\n",
    "            image_path = f\"{synthetic_subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, data_sets, data_transforms):\n",
    "    \n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            data_transforms[x]\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=4,\n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        x: len(image_datasets[x]) \n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    class_names = image_datasets['synthetic_train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return image_datasets, dataloaders, dataset_sizes, class_names, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "        best_test_loss = float('inf')\n",
    "        patience = 2  # Number of epochs to wait for improvement before stopping\n",
    "        test_losses = []\n",
    "        train_losses = []\n",
    "        test_acc = []\n",
    "        train_acc = []\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['synthetic_train', 'test']:\n",
    "                if phase == 'synthetic_train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'synthetic_train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'synthetic_train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double().item() / dataset_sizes[phase]\n",
    "\n",
    "                if phase =='synthetic_train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_acc.append(epoch_acc)\n",
    "                else:\n",
    "                    test_losses.append(epoch_loss)\n",
    "                    test_acc.append(epoch_acc)\n",
    "                    \n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_loss <= best_test_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "                    patience_counter = 0  # Reset counter\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                elif phase == 'test' and epoch_loss > best_test_loss:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                # Early stopping check\n",
    "                #if patience_counter >= patience:\n",
    "                #    print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                #    break\n",
    "\n",
    "        # store results in dataframe\n",
    "        dat = {\n",
    "            \"epoch\": range(len(test_losses)),\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_accuracies\": test_acc,\n",
    "            \"train_accuracies\": train_acc\n",
    "        }\n",
    "\n",
    "        result = pd.DataFrame(data=dat)\n",
    "        print()\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Loss: {best_test_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return result, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through different training scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9931 Acc: 0.5201\n",
      "test Loss: 0.8652 Acc: 0.5734\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8240 Acc: 0.6197\n",
      "test Loss: 0.6810 Acc: 0.7016\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5355 Acc: 0.7781\n",
      "test Loss: 0.4351 Acc: 0.8250\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2752 Acc: 0.8939\n",
      "test Loss: 0.4229 Acc: 0.8547\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1153 Acc: 0.9602\n",
      "test Loss: 0.5833 Acc: 0.8516\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0641 Acc: 0.9783\n",
      "test Loss: 0.4229 Acc: 0.8789\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0521 Acc: 0.9828\n",
      "test Loss: 0.4555 Acc: 0.8883\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0264 Acc: 0.9916\n",
      "test Loss: 0.4658 Acc: 0.8922\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0380 Acc: 0.9883\n",
      "test Loss: 0.7054 Acc: 0.8594\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0384 Acc: 0.9887\n",
      "test Loss: 0.5074 Acc: 0.8758\n",
      "\n",
      "Training complete in 3m 27s\n",
      "Best test Loss: 0.422913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9746 Acc: 0.5258\n",
      "test Loss: 1.0423 Acc: 0.5617\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8047 Acc: 0.6252\n",
      "test Loss: 0.6466 Acc: 0.7273\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5173 Acc: 0.7830\n",
      "test Loss: 0.4618 Acc: 0.8242\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2585 Acc: 0.9049\n",
      "test Loss: 0.5472 Acc: 0.8172\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1103 Acc: 0.9609\n",
      "test Loss: 0.5782 Acc: 0.8383\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0644 Acc: 0.9781\n",
      "test Loss: 0.9182 Acc: 0.8398\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0405 Acc: 0.9873\n",
      "test Loss: 0.5147 Acc: 0.8898\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0387 Acc: 0.9879\n",
      "test Loss: 0.4690 Acc: 0.8805\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0318 Acc: 0.9910\n",
      "test Loss: 0.4942 Acc: 0.8750\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0306 Acc: 0.9902\n",
      "test Loss: 0.5955 Acc: 0.8953\n",
      "\n",
      "Training complete in 3m 33s\n",
      "Best test Loss: 0.461780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0010 Acc: 0.5123\n",
      "test Loss: 0.8964 Acc: 0.5641\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8459 Acc: 0.5869\n",
      "test Loss: 0.7211 Acc: 0.6773\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5841 Acc: 0.7520\n",
      "test Loss: 0.4851 Acc: 0.8250\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2981 Acc: 0.8775\n",
      "test Loss: 0.5211 Acc: 0.8320\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1246 Acc: 0.9553\n",
      "test Loss: 0.4370 Acc: 0.8695\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0568 Acc: 0.9820\n",
      "test Loss: 0.4706 Acc: 0.8828\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0460 Acc: 0.9863\n",
      "test Loss: 0.5494 Acc: 0.8789\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0399 Acc: 0.9871\n",
      "test Loss: 0.5979 Acc: 0.8523\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0284 Acc: 0.9916\n",
      "test Loss: 0.4564 Acc: 0.9125\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0456 Acc: 0.9871\n",
      "test Loss: 0.3956 Acc: 0.8922\n",
      "\n",
      "Training complete in 3m 25s\n",
      "Best test Loss: 0.395627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9962 Acc: 0.5158\n",
      "test Loss: 0.8926 Acc: 0.5742\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7846 Acc: 0.6438\n",
      "test Loss: 0.6154 Acc: 0.7344\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4239 Acc: 0.8289\n",
      "test Loss: 0.3714 Acc: 0.8648\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1864 Acc: 0.9299\n",
      "test Loss: 0.3809 Acc: 0.8781\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0750 Acc: 0.9740\n",
      "test Loss: 0.3516 Acc: 0.9055\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0645 Acc: 0.9775\n",
      "test Loss: 0.3263 Acc: 0.9117\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0313 Acc: 0.9896\n",
      "test Loss: 0.4117 Acc: 0.9062\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0457 Acc: 0.9850\n",
      "test Loss: 0.3602 Acc: 0.9156\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0220 Acc: 0.9951\n",
      "test Loss: 0.4068 Acc: 0.9336\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0360 Acc: 0.9908\n",
      "test Loss: 0.4543 Acc: 0.9055\n",
      "\n",
      "Training complete in 3m 27s\n",
      "Best test Loss: 0.326297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9907 Acc: 0.5236\n",
      "test Loss: 0.9355 Acc: 0.5391\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8196 Acc: 0.6174\n",
      "test Loss: 0.7874 Acc: 0.6750\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5182 Acc: 0.7789\n",
      "test Loss: 0.4507 Acc: 0.8266\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2336 Acc: 0.9121\n",
      "test Loss: 0.5702 Acc: 0.8336\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1009 Acc: 0.9645\n",
      "test Loss: 0.4984 Acc: 0.8828\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0482 Acc: 0.9846\n",
      "test Loss: 0.4642 Acc: 0.8805\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0373 Acc: 0.9855\n",
      "test Loss: 0.4798 Acc: 0.8953\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0306 Acc: 0.9906\n",
      "test Loss: 0.4561 Acc: 0.9109\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0380 Acc: 0.9877\n",
      "test Loss: 0.4761 Acc: 0.8883\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0328 Acc: 0.9896\n",
      "test Loss: 0.4653 Acc: 0.9094\n",
      "\n",
      "Training complete in 3m 24s\n",
      "Best test Loss: 0.450698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9944 Acc: 0.5221\n",
      "test Loss: 0.8704 Acc: 0.5734\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7931 Acc: 0.6391\n",
      "test Loss: 0.6872 Acc: 0.6820\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4854 Acc: 0.7990\n",
      "test Loss: 0.4360 Acc: 0.8320\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2205 Acc: 0.9154\n",
      "test Loss: 0.3734 Acc: 0.8680\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0809 Acc: 0.9727\n",
      "test Loss: 0.4466 Acc: 0.8898\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0644 Acc: 0.9809\n",
      "test Loss: 0.5348 Acc: 0.8734\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0274 Acc: 0.9922\n",
      "test Loss: 0.4969 Acc: 0.8922\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0492 Acc: 0.9836\n",
      "test Loss: 0.4250 Acc: 0.9148\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0378 Acc: 0.9867\n",
      "test Loss: 0.7755 Acc: 0.8430\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0258 Acc: 0.9895\n",
      "test Loss: 0.5207 Acc: 0.9133\n",
      "\n",
      "Training complete in 3m 28s\n",
      "Best test Loss: 0.373430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9853 Acc: 0.5236\n",
      "test Loss: 0.8597 Acc: 0.5773\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8081 Acc: 0.6170\n",
      "test Loss: 0.6609 Acc: 0.7211\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4879 Acc: 0.7936\n",
      "test Loss: 0.4067 Acc: 0.8500\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2186 Acc: 0.9154\n",
      "test Loss: 0.3476 Acc: 0.8828\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0820 Acc: 0.9713\n",
      "test Loss: 0.4038 Acc: 0.9055\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0652 Acc: 0.9799\n",
      "test Loss: 0.4032 Acc: 0.9031\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0445 Acc: 0.9846\n",
      "test Loss: 0.4361 Acc: 0.8984\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0430 Acc: 0.9865\n",
      "test Loss: 0.6472 Acc: 0.8688\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0391 Acc: 0.9867\n",
      "test Loss: 0.4366 Acc: 0.9062\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0329 Acc: 0.9922\n",
      "test Loss: 1.2005 Acc: 0.8086\n",
      "\n",
      "Training complete in 3m 32s\n",
      "Best test Loss: 0.347640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9902 Acc: 0.5252\n",
      "test Loss: 0.8931 Acc: 0.5766\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8408 Acc: 0.5992\n",
      "test Loss: 0.6651 Acc: 0.7078\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5789 Acc: 0.7527\n",
      "test Loss: 0.4748 Acc: 0.8187\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3221 Acc: 0.8672\n",
      "test Loss: 0.4778 Acc: 0.8320\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1362 Acc: 0.9504\n",
      "test Loss: 0.4165 Acc: 0.8820\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0569 Acc: 0.9846\n",
      "test Loss: 0.5474 Acc: 0.8688\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0489 Acc: 0.9863\n",
      "test Loss: 0.7052 Acc: 0.8469\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0249 Acc: 0.9928\n",
      "test Loss: 1.1980 Acc: 0.8234\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0341 Acc: 0.9910\n",
      "test Loss: 0.9457 Acc: 0.8398\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0188 Acc: 0.9932\n",
      "test Loss: 0.7130 Acc: 0.8898\n",
      "\n",
      "Training complete in 3m 28s\n",
      "Best test Loss: 0.416502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9775 Acc: 0.5291\n",
      "test Loss: 0.8908 Acc: 0.5547\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8105 Acc: 0.6275\n",
      "test Loss: 0.7318 Acc: 0.6727\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5124 Acc: 0.7934\n",
      "test Loss: 0.4484 Acc: 0.8273\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2562 Acc: 0.9023\n",
      "test Loss: 0.4175 Acc: 0.8516\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1008 Acc: 0.9639\n",
      "test Loss: 0.4564 Acc: 0.8680\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0577 Acc: 0.9809\n",
      "test Loss: 0.3675 Acc: 0.8898\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0560 Acc: 0.9811\n",
      "test Loss: 0.4952 Acc: 0.8742\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0393 Acc: 0.9873\n",
      "test Loss: 0.4338 Acc: 0.8945\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0213 Acc: 0.9922\n",
      "test Loss: 0.8539 Acc: 0.8523\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0529 Acc: 0.9846\n",
      "test Loss: 0.6016 Acc: 0.8906\n",
      "\n",
      "Training complete in 3m 29s\n",
      "Best test Loss: 0.367514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9781 Acc: 0.5207\n",
      "test Loss: 0.9375 Acc: 0.5492\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7918 Acc: 0.6373\n",
      "test Loss: 0.6347 Acc: 0.7164\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5038 Acc: 0.7930\n",
      "test Loss: 0.4032 Acc: 0.8492\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2485 Acc: 0.9055\n",
      "test Loss: 0.4249 Acc: 0.8703\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1103 Acc: 0.9602\n",
      "test Loss: 0.5067 Acc: 0.8711\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0782 Acc: 0.9730\n",
      "test Loss: 0.3868 Acc: 0.8859\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0323 Acc: 0.9881\n",
      "test Loss: 0.5872 Acc: 0.8703\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0535 Acc: 0.9807\n",
      "test Loss: 0.4023 Acc: 0.8844\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0343 Acc: 0.9889\n",
      "test Loss: 0.5699 Acc: 0.8750\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0163 Acc: 0.9959\n",
      "test Loss: 2.1251 Acc: 0.7492\n",
      "\n",
      "Training complete in 3m 32s\n",
      "Best test Loss: 0.386797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 1.0139 Acc: 0.5027\n",
      "test Loss: 0.9437 Acc: 0.5227\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9267 Acc: 0.5520\n",
      "test Loss: 0.8437 Acc: 0.5766\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8298 Acc: 0.6055\n",
      "test Loss: 0.8282 Acc: 0.6203\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7030 Acc: 0.6906\n",
      "test Loss: 0.5726 Acc: 0.7539\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5501 Acc: 0.7643\n",
      "test Loss: 0.5064 Acc: 0.8102\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4423 Acc: 0.8279\n",
      "test Loss: 0.4462 Acc: 0.8266\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3274 Acc: 0.8742\n",
      "test Loss: 0.4189 Acc: 0.8422\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2464 Acc: 0.9068\n",
      "test Loss: 0.4028 Acc: 0.8594\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1738 Acc: 0.9389\n",
      "test Loss: 0.4277 Acc: 0.8750\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1382 Acc: 0.9512\n",
      "test Loss: 0.4094 Acc: 0.8859\n",
      "\n",
      "Training complete in 3m 31s\n",
      "Best test Loss: 0.402794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9982 Acc: 0.5109\n",
      "test Loss: 0.9344 Acc: 0.5461\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9081 Acc: 0.5555\n",
      "test Loss: 0.8860 Acc: 0.5789\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7900 Acc: 0.6283\n",
      "test Loss: 0.6501 Acc: 0.7008\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6094 Acc: 0.7396\n",
      "test Loss: 0.5375 Acc: 0.7797\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4505 Acc: 0.8098\n",
      "test Loss: 0.4793 Acc: 0.8180\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2983 Acc: 0.8883\n",
      "test Loss: 0.4184 Acc: 0.8586\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2200 Acc: 0.9199\n",
      "test Loss: 0.4235 Acc: 0.8609\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1384 Acc: 0.9551\n",
      "test Loss: 0.3848 Acc: 0.8961\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1134 Acc: 0.9617\n",
      "test Loss: 0.4752 Acc: 0.8648\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0809 Acc: 0.9729\n",
      "test Loss: 0.4243 Acc: 0.8906\n",
      "\n",
      "Training complete in 3m 31s\n",
      "Best test Loss: 0.384807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9862 Acc: 0.5201\n",
      "test Loss: 0.8906 Acc: 0.5531\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8886 Acc: 0.5756\n",
      "test Loss: 0.7622 Acc: 0.6406\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7712 Acc: 0.6381\n",
      "test Loss: 0.6726 Acc: 0.7031\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6070 Acc: 0.7344\n",
      "test Loss: 0.4949 Acc: 0.7969\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4346 Acc: 0.8236\n",
      "test Loss: 0.4540 Acc: 0.8406\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3199 Acc: 0.8770\n",
      "test Loss: 0.4180 Acc: 0.8625\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2296 Acc: 0.9213\n",
      "test Loss: 0.3471 Acc: 0.8867\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1647 Acc: 0.9418\n",
      "test Loss: 0.3664 Acc: 0.8820\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1173 Acc: 0.9582\n",
      "test Loss: 0.4826 Acc: 0.8766\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1073 Acc: 0.9652\n",
      "test Loss: 0.3747 Acc: 0.8914\n",
      "\n",
      "Training complete in 3m 40s\n",
      "Best test Loss: 0.347071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9963 Acc: 0.5100\n",
      "test Loss: 0.9058 Acc: 0.5516\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9078 Acc: 0.5531\n",
      "test Loss: 0.8464 Acc: 0.5719\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8267 Acc: 0.6033\n",
      "test Loss: 0.7979 Acc: 0.6102\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7232 Acc: 0.6576\n",
      "test Loss: 0.6874 Acc: 0.6930\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5876 Acc: 0.7436\n",
      "test Loss: 0.6642 Acc: 0.7508\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4588 Acc: 0.8160\n",
      "test Loss: 0.5051 Acc: 0.8102\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3245 Acc: 0.8701\n",
      "test Loss: 0.5201 Acc: 0.8172\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2469 Acc: 0.9094\n",
      "test Loss: 0.4504 Acc: 0.8438\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1822 Acc: 0.9371\n",
      "test Loss: 0.5321 Acc: 0.8445\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1456 Acc: 0.9496\n",
      "test Loss: 0.6990 Acc: 0.8281\n",
      "\n",
      "Training complete in 3m 27s\n",
      "Best test Loss: 0.450390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9839 Acc: 0.5174\n",
      "test Loss: 0.8956 Acc: 0.5461\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8920 Acc: 0.5660\n",
      "test Loss: 0.8206 Acc: 0.6000\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8062 Acc: 0.6139\n",
      "test Loss: 0.7898 Acc: 0.6422\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6454 Acc: 0.7121\n",
      "test Loss: 0.5448 Acc: 0.7664\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4676 Acc: 0.8121\n",
      "test Loss: 0.4613 Acc: 0.8336\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3258 Acc: 0.8688\n",
      "test Loss: 0.4708 Acc: 0.8438\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2407 Acc: 0.9146\n",
      "test Loss: 0.4267 Acc: 0.8539\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1675 Acc: 0.9404\n",
      "test Loss: 0.4224 Acc: 0.8641\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1131 Acc: 0.9617\n",
      "test Loss: 0.4291 Acc: 0.8789\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0891 Acc: 0.9695\n",
      "test Loss: 0.5189 Acc: 0.8789\n",
      "\n",
      "Training complete in 3m 33s\n",
      "Best test Loss: 0.422392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9928 Acc: 0.5061\n",
      "test Loss: 0.9051 Acc: 0.5547\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9088 Acc: 0.5615\n",
      "test Loss: 0.8510 Acc: 0.5938\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8127 Acc: 0.6135\n",
      "test Loss: 0.7713 Acc: 0.6273\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6682 Acc: 0.6926\n",
      "test Loss: 0.6330 Acc: 0.7289\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.5007 Acc: 0.7945\n",
      "test Loss: 0.5275 Acc: 0.7859\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3582 Acc: 0.8590\n",
      "test Loss: 0.5052 Acc: 0.8187\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2559 Acc: 0.9090\n",
      "test Loss: 0.4500 Acc: 0.8633\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1893 Acc: 0.9389\n",
      "test Loss: 0.5343 Acc: 0.8117\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1466 Acc: 0.9521\n",
      "test Loss: 0.5173 Acc: 0.8492\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0961 Acc: 0.9680\n",
      "test Loss: 0.5217 Acc: 0.8586\n",
      "\n",
      "Training complete in 3m 27s\n",
      "Best test Loss: 0.450006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9849 Acc: 0.5271\n",
      "test Loss: 0.9033 Acc: 0.5484\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8783 Acc: 0.5773\n",
      "test Loss: 0.8228 Acc: 0.5836\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7829 Acc: 0.6320\n",
      "test Loss: 0.7182 Acc: 0.6852\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6355 Acc: 0.7186\n",
      "test Loss: 0.6388 Acc: 0.7383\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4829 Acc: 0.7988\n",
      "test Loss: 0.5626 Acc: 0.7742\n",
      "Epoch 5/9\n",
      "----------\n",
      "synthetic_train Loss: 0.3478 Acc: 0.8592\n",
      "test Loss: 0.4690 Acc: 0.8367\n",
      "Epoch 6/9\n",
      "----------\n",
      "synthetic_train Loss: 0.2516 Acc: 0.9020\n",
      "test Loss: 0.5236 Acc: 0.8250\n",
      "Epoch 7/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1841 Acc: 0.9332\n",
      "test Loss: 0.3679 Acc: 0.8773\n",
      "Epoch 8/9\n",
      "----------\n",
      "synthetic_train Loss: 0.1367 Acc: 0.9520\n",
      "test Loss: 0.3638 Acc: 0.8875\n",
      "Epoch 9/9\n",
      "----------\n",
      "synthetic_train Loss: 0.0896 Acc: 0.9717\n",
      "test Loss: 0.4437 Acc: 0.8680\n",
      "\n",
      "Training complete in 3m 18s\n",
      "Best test Loss: 0.363795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "synthetic_train Loss: 0.9889 Acc: 0.5203\n",
      "test Loss: 0.9267 Acc: 0.5406\n",
      "Epoch 1/9\n",
      "----------\n",
      "synthetic_train Loss: 0.8977 Acc: 0.5693\n",
      "test Loss: 0.8327 Acc: 0.6219\n",
      "Epoch 2/9\n",
      "----------\n",
      "synthetic_train Loss: 0.7842 Acc: 0.6414\n",
      "test Loss: 0.6547 Acc: 0.6953\n",
      "Epoch 3/9\n",
      "----------\n",
      "synthetic_train Loss: 0.6145 Acc: 0.7354\n",
      "test Loss: 0.5532 Acc: 0.7766\n",
      "Epoch 4/9\n",
      "----------\n",
      "synthetic_train Loss: 0.4435 Acc: 0.8266\n",
      "test Loss: 0.4684 Acc: 0.8195\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "num_sims = 10\n",
    "train_percs = [0.6, 0.6, 0.4, 0.4]\n",
    "synth_percs = [0.4, 0.0, 0.6, 0.0]\n",
    "transforms = {\n",
    "    'minimal': minimal_transforms,\n",
    "    'basic': basic_transforms,\n",
    "    'auto': auto_transforms\n",
    "}\n",
    "\n",
    "for train_percentage, synthetic_percentage in zip(train_percs, synth_percs):\n",
    "    for active_transform in transforms.keys():\n",
    "        df_all_results = pd.DataFrame()\n",
    "        for n in range(num_sims):\n",
    "    \n",
    "            # make the synthetic training dataset\n",
    "            makeSyntheticTrain(\n",
    "                train_directory='../data/alzheimer_mri/train',\n",
    "                synthetic_train_directory='../data/alzheimer_mri/synthetic_train', \n",
    "                train_percentage=train_percentage, \n",
    "                synthetic_percentage=synthetic_percentage\n",
    "            )\n",
    "\n",
    "            # get and load datasets\n",
    "            data_dir = '../data/alzheimer_mri'\n",
    "            data_sets = ['synthetic_train','test']\n",
    "            image_datasets, dataloaders, dataset_sizes, class_names, device = get_data(\n",
    "                data_dir=data_dir, \n",
    "                data_sets=data_sets, \n",
    "                data_transforms=transforms.get(active_transform)\n",
    "            )\n",
    "\n",
    "            # instantiate model\n",
    "            model = cnn.CNN(in_channels=1, num_classes=4)\n",
    "\n",
    "            # Set the size of each output sample to nn.Linear(num_ftrs, len(class_names))\n",
    "            #num_ftrs = 4 #model.fc.in_features\n",
    "            #model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "            model = model.to(device)\n",
    "\n",
    "            # train the model\n",
    "            df_results,_ = model = train_model(\n",
    "                model=model, \n",
    "                criterion = nn.CrossEntropyLoss(),\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001), \n",
    "                dataloaders=dataloaders,\n",
    "                dataset_sizes=dataset_sizes,\n",
    "                num_epochs=num_epochs\n",
    "            )\n",
    "\n",
    "            df_results['train_percentage'] = train_percentage\n",
    "            df_results['synth_percentage'] = synthetic_percentage\n",
    "            df_results['transform'] = active_transform\n",
    "            df_results['sim_num'] = n\n",
    "            df_results['category'] = df_results.apply(lambda row: row['transform']+'_'+str(row['train_percentage'])+'_'+str(row['synth_percentage']), axis=1)\n",
    "            df_all_results = pd.concat([df_all_results, df_results],ignore_index=True)\n",
    "        df_all_results.to_csv('../results/results_cnn_'+active_transform+'_'+str(train_percentage)+'_'+str(synthetic_percentage)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
