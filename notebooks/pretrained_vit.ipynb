{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fd4f31542e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from custom_models import vit\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from vit_pytorch import ViT\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from tempfile import TemporaryDirectory\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations to loop through\n",
    "minimal_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "basic_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "auto_transforms = {\n",
    "    'synthetic_train': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n",
    "        v2.Grayscale(num_output_channels=3),\n",
    "        v2.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5]),\n",
    "        v2.Resize((224, 224))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Set with Real/Synthetic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSyntheticTrain(train_directory, synthetic_train_directory, train_dict, synthetic_dict):\n",
    "\n",
    "    # Remove any existing images in directory\n",
    "    try:\n",
    "        shutil.rmtree(synthetic_train_directory)\n",
    "    except:\n",
    "        print(\"directory does not exist\")\n",
    "\n",
    "    # Loop through subfolders, generate synthetic images\n",
    "    subfolders = [f for f in os.listdir(train_directory)]\n",
    "\n",
    "    for s in subfolders:\n",
    "        # for each subfolder in the train directory, make the same in the synthetic train directory\n",
    "        os.makedirs(f\"{synthetic_train_directory}/{s}\", exist_ok=True)\n",
    "        \n",
    "        # get a random sample from each subfolder\n",
    "        subfolder_path = f\"{train_directory}/{s}\"\n",
    "        files = os.listdir(subfolder_path)\n",
    "        sample_files = random.sample(files, round(len(files)*train_dict[s]))\n",
    "        \n",
    "        # create synthetic sample based on sampled original images\n",
    "        synthetic_subfolder_path = subfolder_path.replace('train','synthetic')\n",
    "        synthetic_files = [f for f in os.listdir(synthetic_subfolder_path) if int(f.replace('.png','').split('_')[1]) in [int(f.replace('.png','').split('_')[1]) for f in sample_files]]\n",
    "        synthetic_sample_files = random.sample(synthetic_files, round(len(files)*synthetic_dict[s]))\n",
    "        \n",
    "        # Move sample files to synthetic directory\n",
    "        for f in sample_files:\n",
    "            \n",
    "            image_path = f\"{subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])\n",
    "\n",
    "        # Move synthetic sample files to synthetic directory\n",
    "        for f in synthetic_sample_files:\n",
    "\n",
    "            image_path = f\"{synthetic_subfolder_path}/{f}\"\n",
    "            destination_directory = f\"{synthetic_train_directory}/{s}/\"\n",
    "            shutil.copyfile(image_path, destination_directory + image_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, data_sets, data_transforms):\n",
    "    \n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            data_transforms[x]\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x], \n",
    "            batch_size=16,\n",
    "            shuffle=True\n",
    "        )\n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        x: len(image_datasets[x]) \n",
    "        for x in data_sets\n",
    "    }\n",
    "\n",
    "    class_names = image_datasets['synthetic_train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return image_datasets, dataloaders, dataset_sizes, class_names, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "        best_test_loss = float('inf')\n",
    "        patience = 2  # Number of epochs to wait for improvement before stopping\n",
    "        test_losses = []\n",
    "        train_losses = []\n",
    "        test_acc = []\n",
    "        train_acc = []\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['synthetic_train', 'test']:\n",
    "                if phase == 'synthetic_train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'synthetic_train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'synthetic_train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double().item() / dataset_sizes[phase]\n",
    "\n",
    "                if phase =='synthetic_train':\n",
    "                    train_losses.append(epoch_loss)\n",
    "                    train_acc.append(epoch_acc)\n",
    "                else:\n",
    "                    test_losses.append(epoch_loss)\n",
    "                    test_acc.append(epoch_acc)\n",
    "                    \n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_loss <= best_test_loss:\n",
    "                    best_test_loss = epoch_loss\n",
    "                    patience_counter = 0  # Reset counter\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "                elif phase == 'test' and epoch_loss > best_test_loss:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                    # Early stopping check\n",
    "                    if patience_counter >= patience:\n",
    "                        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                        break\n",
    "\n",
    "        # store results in dataframe\n",
    "        dat = {\n",
    "            \"epoch\": range(len(test_losses)),\n",
    "            \"test_losses\": test_losses,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"test_accuracies\": test_acc,\n",
    "            \"train_accuracies\": train_acc\n",
    "        }\n",
    "\n",
    "        result = pd.DataFrame(data=dat)\n",
    "        print()\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Loss: {best_test_loss:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return result, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through different training scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1914 Acc: 0.4622\n",
      "test Loss: 1.0944 Acc: 0.4781\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0840 Acc: 0.4614\n",
      "test Loss: 1.1497 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0663 Acc: 0.4678\n",
      "test Loss: 1.0358 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0516 Acc: 0.4792\n",
      "test Loss: 1.0386 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0420 Acc: 0.4951\n",
      "test Loss: 1.0608 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0418 Acc: 0.4873\n",
      "test Loss: 1.0483 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0315 Acc: 0.4949\n",
      "test Loss: 1.0537 Acc: 0.4961\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0415 Acc: 0.4905\n",
      "test Loss: 1.0493 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0342 Acc: 0.4895\n",
      "test Loss: 1.0627 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0397 Acc: 0.4922\n",
      "test Loss: 1.0315 Acc: 0.4930\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0327 Acc: 0.4963\n",
      "test Loss: 1.0322 Acc: 0.4992\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0349 Acc: 0.5020\n",
      "test Loss: 1.0386 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0308 Acc: 0.5037\n",
      "test Loss: 1.0338 Acc: 0.4984\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0324 Acc: 0.4985\n",
      "test Loss: 1.0409 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0360 Acc: 0.4934\n",
      "test Loss: 1.0376 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 10s\n",
      "Best test Loss: 1.031468\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1854 Acc: 0.4541\n",
      "test Loss: 1.0539 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0602 Acc: 0.4717\n",
      "test Loss: 1.0488 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0665 Acc: 0.4834\n",
      "test Loss: 1.0428 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0568 Acc: 0.4741\n",
      "test Loss: 1.0621 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0465 Acc: 0.4941\n",
      "test Loss: 1.0534 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0462 Acc: 0.4839\n",
      "test Loss: 1.0388 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0395 Acc: 0.4915\n",
      "test Loss: 1.0422 Acc: 0.4984\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0372 Acc: 0.4971\n",
      "test Loss: 1.0404 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0363 Acc: 0.4907\n",
      "test Loss: 1.0438 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0295 Acc: 0.5039\n",
      "test Loss: 1.0340 Acc: 0.4961\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0268 Acc: 0.5010\n",
      "test Loss: 1.2034 Acc: 0.4953\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0217 Acc: 0.5002\n",
      "test Loss: 1.0404 Acc: 0.4984\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0329 Acc: 0.4934\n",
      "test Loss: 1.0517 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0316 Acc: 0.4961\n",
      "test Loss: 1.0301 Acc: 0.4953\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0381 Acc: 0.4973\n",
      "test Loss: 1.0374 Acc: 0.4953\n",
      "\n",
      "Training complete in 25m 11s\n",
      "Best test Loss: 1.030091\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1796 Acc: 0.4702\n",
      "test Loss: 1.2059 Acc: 0.4852\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0345 Acc: 0.5100\n",
      "test Loss: 1.0367 Acc: 0.4930\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9955 Acc: 0.5234\n",
      "test Loss: 0.9845 Acc: 0.5195\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9916 Acc: 0.5166\n",
      "test Loss: 1.0516 Acc: 0.5125\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9864 Acc: 0.5215\n",
      "test Loss: 1.0430 Acc: 0.4289\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9962 Acc: 0.5188\n",
      "test Loss: 0.9987 Acc: 0.5328\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9955 Acc: 0.5190\n",
      "test Loss: 0.9987 Acc: 0.5227\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0016 Acc: 0.5154\n",
      "test Loss: 1.0160 Acc: 0.5016\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0089 Acc: 0.5039\n",
      "test Loss: 1.0122 Acc: 0.5055\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0322 Acc: 0.5046\n",
      "test Loss: 1.0083 Acc: 0.5234\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0054 Acc: 0.5107\n",
      "test Loss: 0.9928 Acc: 0.5430\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9967 Acc: 0.5137\n",
      "test Loss: 1.0030 Acc: 0.5180\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0061 Acc: 0.5129\n",
      "test Loss: 1.0050 Acc: 0.5180\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0103 Acc: 0.5024\n",
      "test Loss: 1.0639 Acc: 0.4914\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0071 Acc: 0.5083\n",
      "test Loss: 1.0049 Acc: 0.5109\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 24m 52s\n",
      "Best test Loss: 0.984510\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1940 Acc: 0.4719\n",
      "test Loss: 1.0459 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0931 Acc: 0.4573\n",
      "test Loss: 1.0786 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0708 Acc: 0.4714\n",
      "test Loss: 1.0599 Acc: 0.4359\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0543 Acc: 0.4714\n",
      "test Loss: 1.0519 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0511 Acc: 0.4758\n",
      "test Loss: 1.1074 Acc: 0.4883\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0399 Acc: 0.4988\n",
      "test Loss: 1.0682 Acc: 0.4984\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0462 Acc: 0.4824\n",
      "test Loss: 1.0453 Acc: 0.4953\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0321 Acc: 0.4875\n",
      "test Loss: 1.1533 Acc: 0.4125\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0195 Acc: 0.5000\n",
      "test Loss: 0.9947 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0162 Acc: 0.5049\n",
      "test Loss: 1.0030 Acc: 0.4992\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0364 Acc: 0.4924\n",
      "test Loss: 1.0355 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0370 Acc: 0.4917\n",
      "test Loss: 1.0195 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0431 Acc: 0.4897\n",
      "test Loss: 1.0429 Acc: 0.4938\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0423 Acc: 0.4956\n",
      "test Loss: 1.0552 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0477 Acc: 0.4834\n",
      "test Loss: 1.0395 Acc: 0.4961\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 24m 47s\n",
      "Best test Loss: 0.994693\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2129 Acc: 0.4519\n",
      "test Loss: 1.1142 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0707 Acc: 0.4771\n",
      "test Loss: 1.1160 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0629 Acc: 0.4802\n",
      "test Loss: 1.0561 Acc: 0.4680\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0370 Acc: 0.4900\n",
      "test Loss: 1.0374 Acc: 0.4906\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0394 Acc: 0.4929\n",
      "test Loss: 1.0070 Acc: 0.5055\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0048 Acc: 0.5146\n",
      "test Loss: 0.9742 Acc: 0.5461\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9962 Acc: 0.5071\n",
      "test Loss: 1.0313 Acc: 0.4641\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9927 Acc: 0.5100\n",
      "test Loss: 0.9770 Acc: 0.5117\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 0.9783 Acc: 0.5137\n",
      "test Loss: 0.9774 Acc: 0.5312\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0148 Acc: 0.4902\n",
      "test Loss: 1.0087 Acc: 0.5375\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0306 Acc: 0.4934\n",
      "test Loss: 1.0318 Acc: 0.4688\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0215 Acc: 0.4954\n",
      "test Loss: 1.0015 Acc: 0.4984\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0256 Acc: 0.4976\n",
      "test Loss: 1.0169 Acc: 0.5039\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0214 Acc: 0.5051\n",
      "test Loss: 1.0188 Acc: 0.5078\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0259 Acc: 0.4939\n",
      "test Loss: 1.0266 Acc: 0.5125\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 24m 44s\n",
      "Best test Loss: 0.974161\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1821 Acc: 0.4622\n",
      "test Loss: 1.1087 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0821 Acc: 0.4636\n",
      "test Loss: 1.1539 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0727 Acc: 0.4629\n",
      "test Loss: 1.0482 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0555 Acc: 0.4878\n",
      "test Loss: 1.0558 Acc: 0.3609\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0558 Acc: 0.4783\n",
      "test Loss: 1.0578 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0478 Acc: 0.4878\n",
      "test Loss: 1.1116 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0477 Acc: 0.4802\n",
      "test Loss: 1.0511 Acc: 0.3602\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0478 Acc: 0.4836\n",
      "test Loss: 1.0400 Acc: 0.4953\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0440 Acc: 0.4963\n",
      "test Loss: 1.0420 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0418 Acc: 0.4954\n",
      "test Loss: 1.0419 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0411 Acc: 0.4968\n",
      "test Loss: 1.0425 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0406 Acc: 0.4958\n",
      "test Loss: 1.0436 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0403 Acc: 0.5015\n",
      "test Loss: 1.0404 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0407 Acc: 0.5002\n",
      "test Loss: 1.0449 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0389 Acc: 0.4949\n",
      "test Loss: 1.0422 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 17s\n",
      "Best test Loss: 1.039986\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2061 Acc: 0.4529\n",
      "test Loss: 1.0477 Acc: 0.5062\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0703 Acc: 0.4751\n",
      "test Loss: 1.0759 Acc: 0.3633\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0596 Acc: 0.4849\n",
      "test Loss: 1.0527 Acc: 0.5000\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0334 Acc: 0.4958\n",
      "test Loss: 1.1293 Acc: 0.3859\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0296 Acc: 0.4934\n",
      "test Loss: 1.0164 Acc: 0.5047\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0190 Acc: 0.4990\n",
      "test Loss: 1.0187 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0199 Acc: 0.4971\n",
      "test Loss: 1.0491 Acc: 0.4547\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0185 Acc: 0.4927\n",
      "test Loss: 1.0268 Acc: 0.4820\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0355 Acc: 0.4958\n",
      "test Loss: 1.0354 Acc: 0.4820\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0253 Acc: 0.5005\n",
      "test Loss: 0.9985 Acc: 0.5039\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0132 Acc: 0.5007\n",
      "test Loss: 1.0254 Acc: 0.4844\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0273 Acc: 0.4954\n",
      "test Loss: 1.0142 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0193 Acc: 0.4990\n",
      "test Loss: 1.0152 Acc: 0.5055\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0183 Acc: 0.4980\n",
      "test Loss: 1.0403 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0234 Acc: 0.4849\n",
      "test Loss: 1.0280 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 7s\n",
      "Best test Loss: 0.998459\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1903 Acc: 0.4539\n",
      "test Loss: 1.1133 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0642 Acc: 0.4800\n",
      "test Loss: 1.0325 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0452 Acc: 0.4841\n",
      "test Loss: 1.0503 Acc: 0.4922\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0282 Acc: 0.5042\n",
      "test Loss: 1.0476 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0276 Acc: 0.4954\n",
      "test Loss: 1.0423 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0259 Acc: 0.4976\n",
      "test Loss: 1.0312 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0216 Acc: 0.4958\n",
      "test Loss: 1.0584 Acc: 0.4953\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0223 Acc: 0.5103\n",
      "test Loss: 1.0472 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0246 Acc: 0.5027\n",
      "test Loss: 1.0220 Acc: 0.5141\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0155 Acc: 0.4971\n",
      "test Loss: 1.0278 Acc: 0.5031\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0201 Acc: 0.4985\n",
      "test Loss: 1.0178 Acc: 0.5023\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0123 Acc: 0.5039\n",
      "test Loss: 1.0483 Acc: 0.4945\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0134 Acc: 0.5020\n",
      "test Loss: 1.0398 Acc: 0.4867\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0159 Acc: 0.5066\n",
      "test Loss: 1.0545 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0070 Acc: 0.5093\n",
      "test Loss: 1.0236 Acc: 0.5023\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 11s\n",
      "Best test Loss: 1.017828\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2603 Acc: 0.4495\n",
      "test Loss: 1.0425 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0940 Acc: 0.4668\n",
      "test Loss: 1.0421 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0784 Acc: 0.4722\n",
      "test Loss: 1.0440 Acc: 0.4813\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0544 Acc: 0.4783\n",
      "test Loss: 1.0478 Acc: 0.4742\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0511 Acc: 0.4905\n",
      "test Loss: 1.0435 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0497 Acc: 0.4846\n",
      "test Loss: 1.0591 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0473 Acc: 0.4937\n",
      "test Loss: 1.0397 Acc: 0.4953\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0426 Acc: 0.4941\n",
      "test Loss: 1.0393 Acc: 0.4953\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0431 Acc: 0.4983\n",
      "test Loss: 1.0438 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0417 Acc: 0.4932\n",
      "test Loss: 1.0434 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0427 Acc: 0.4961\n",
      "test Loss: 1.0397 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0414 Acc: 0.5012\n",
      "test Loss: 1.0456 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0406 Acc: 0.4968\n",
      "test Loss: 1.0575 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0389 Acc: 0.4944\n",
      "test Loss: 1.0429 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0376 Acc: 0.5012\n",
      "test Loss: 1.0435 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 15s\n",
      "Best test Loss: 1.039329\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2156 Acc: 0.4485\n",
      "test Loss: 1.1500 Acc: 0.3586\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0845 Acc: 0.4587\n",
      "test Loss: 1.0455 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0653 Acc: 0.4575\n",
      "test Loss: 1.0633 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0553 Acc: 0.4795\n",
      "test Loss: 1.0595 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0558 Acc: 0.4810\n",
      "test Loss: 1.1258 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0484 Acc: 0.4907\n",
      "test Loss: 1.0404 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0425 Acc: 0.4946\n",
      "test Loss: 1.0404 Acc: 0.4953\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0367 Acc: 0.5000\n",
      "test Loss: 1.0427 Acc: 0.4953\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0388 Acc: 0.4905\n",
      "test Loss: 1.0393 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0400 Acc: 0.4998\n",
      "test Loss: 1.0362 Acc: 0.4969\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0403 Acc: 0.4976\n",
      "test Loss: 1.0453 Acc: 0.5016\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0426 Acc: 0.4998\n",
      "test Loss: 1.0388 Acc: 0.4945\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0380 Acc: 0.4927\n",
      "test Loss: 1.0288 Acc: 0.4953\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0407 Acc: 0.4893\n",
      "test Loss: 1.0527 Acc: 0.4953\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0418 Acc: 0.4973\n",
      "test Loss: 1.0388 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 16s\n",
      "Best test Loss: 1.028752\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1974 Acc: 0.4539\n",
      "test Loss: 1.1419 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0853 Acc: 0.4700\n",
      "test Loss: 1.0823 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0608 Acc: 0.4746\n",
      "test Loss: 1.0902 Acc: 0.4945\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0470 Acc: 0.4919\n",
      "test Loss: 1.0369 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0481 Acc: 0.4976\n",
      "test Loss: 1.0388 Acc: 0.4953\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0428 Acc: 0.5012\n",
      "test Loss: 1.0384 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0370 Acc: 0.4995\n",
      "test Loss: 1.0393 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0408 Acc: 0.4895\n",
      "test Loss: 1.0444 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0413 Acc: 0.4980\n",
      "test Loss: 1.0407 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0391 Acc: 0.5017\n",
      "test Loss: 1.0391 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0421 Acc: 0.4888\n",
      "test Loss: 1.0382 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0400 Acc: 0.4961\n",
      "test Loss: 1.0691 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0418 Acc: 0.5000\n",
      "test Loss: 1.0460 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0401 Acc: 0.4924\n",
      "test Loss: 1.0449 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0413 Acc: 0.4983\n",
      "test Loss: 1.0403 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 52s\n",
      "Best test Loss: 1.036898\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1861 Acc: 0.4512\n",
      "test Loss: 1.1532 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0895 Acc: 0.4453\n",
      "test Loss: 1.0862 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0580 Acc: 0.4839\n",
      "test Loss: 1.0519 Acc: 0.3602\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0490 Acc: 0.4812\n",
      "test Loss: 1.0439 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0406 Acc: 0.4934\n",
      "test Loss: 1.0308 Acc: 0.4953\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0411 Acc: 0.4990\n",
      "test Loss: 1.0493 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0408 Acc: 0.5000\n",
      "test Loss: 1.0461 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0403 Acc: 0.4985\n",
      "test Loss: 1.0598 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0396 Acc: 0.4971\n",
      "test Loss: 1.0866 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0425 Acc: 0.5012\n",
      "test Loss: 1.0475 Acc: 0.4977\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0365 Acc: 0.4971\n",
      "test Loss: 1.0817 Acc: 0.3578\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0398 Acc: 0.4988\n",
      "test Loss: 1.0496 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0416 Acc: 0.4995\n",
      "test Loss: 1.0512 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0399 Acc: 0.4998\n",
      "test Loss: 1.0470 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0419 Acc: 0.4966\n",
      "test Loss: 1.0481 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 52s\n",
      "Best test Loss: 1.030774\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2870 Acc: 0.4575\n",
      "test Loss: 1.1300 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1064 Acc: 0.4497\n",
      "test Loss: 1.1238 Acc: 0.3586\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0808 Acc: 0.4609\n",
      "test Loss: 1.1284 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0642 Acc: 0.4651\n",
      "test Loss: 1.1099 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0546 Acc: 0.4883\n",
      "test Loss: 1.0507 Acc: 0.4953\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0563 Acc: 0.4800\n",
      "test Loss: 1.0625 Acc: 0.4953\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0495 Acc: 0.4841\n",
      "test Loss: 1.0532 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0447 Acc: 0.4890\n",
      "test Loss: 1.0282 Acc: 0.4953\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0434 Acc: 0.4924\n",
      "test Loss: 1.0505 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0426 Acc: 0.4846\n",
      "test Loss: 1.0421 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0388 Acc: 0.4954\n",
      "test Loss: 1.0458 Acc: 0.4945\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0395 Acc: 0.4976\n",
      "test Loss: 1.0240 Acc: 0.4953\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0389 Acc: 0.4949\n",
      "test Loss: 1.0640 Acc: 0.4953\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0399 Acc: 0.4973\n",
      "test Loss: 1.0314 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0375 Acc: 0.5010\n",
      "test Loss: 1.0349 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 59s\n",
      "Best test Loss: 1.023969\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.2358 Acc: 0.4551\n",
      "test Loss: 1.1646 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0869 Acc: 0.4722\n",
      "test Loss: 1.0562 Acc: 0.3586\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0803 Acc: 0.4688\n",
      "test Loss: 1.0895 Acc: 0.4953\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0502 Acc: 0.4817\n",
      "test Loss: 1.0507 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0542 Acc: 0.4817\n",
      "test Loss: 1.0654 Acc: 0.4953\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0468 Acc: 0.4893\n",
      "test Loss: 1.0558 Acc: 0.3609\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0457 Acc: 0.4861\n",
      "test Loss: 1.0407 Acc: 0.4953\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0423 Acc: 0.4971\n",
      "test Loss: 1.0440 Acc: 0.4953\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0419 Acc: 0.4963\n",
      "test Loss: 1.0399 Acc: 0.4953\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0433 Acc: 0.4929\n",
      "test Loss: 1.0467 Acc: 0.4953\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0423 Acc: 0.4963\n",
      "test Loss: 1.0506 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0411 Acc: 0.4976\n",
      "test Loss: 1.0374 Acc: 0.4953\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0404 Acc: 0.4963\n",
      "test Loss: 1.0406 Acc: 0.4953\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0390 Acc: 0.4976\n",
      "test Loss: 1.0310 Acc: 0.4953\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0455 Acc: 0.4958\n",
      "test Loss: 1.0402 Acc: 0.4953\n",
      "\n",
      "Training complete in 26m 1s\n",
      "Best test Loss: 1.030999\n",
      "Epoch 0/14\n",
      "----------\n",
      "synthetic_train Loss: 1.1823 Acc: 0.4741\n",
      "test Loss: 1.0505 Acc: 0.4953\n",
      "Epoch 1/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0982 Acc: 0.4636\n",
      "test Loss: 1.0490 Acc: 0.4953\n",
      "Epoch 2/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0574 Acc: 0.4841\n",
      "test Loss: 1.0331 Acc: 0.5102\n",
      "Epoch 3/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0560 Acc: 0.4768\n",
      "test Loss: 1.0566 Acc: 0.4953\n",
      "Epoch 4/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0541 Acc: 0.4773\n",
      "test Loss: 1.0762 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 5/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0438 Acc: 0.4905\n",
      "test Loss: 1.0578 Acc: 0.4477\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 6/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0419 Acc: 0.4915\n",
      "test Loss: 1.0416 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 7/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0400 Acc: 0.4976\n",
      "test Loss: 1.0482 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 8/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0417 Acc: 0.5005\n",
      "test Loss: 1.0363 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 9/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0378 Acc: 0.5010\n",
      "test Loss: 1.0583 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 10/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0427 Acc: 0.4895\n",
      "test Loss: 1.0515 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 11/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0381 Acc: 0.4988\n",
      "test Loss: 1.0461 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "Epoch 12/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0371 Acc: 0.4944\n",
      "test Loss: 1.0260 Acc: 0.4953\n",
      "Epoch 13/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0481 Acc: 0.4888\n",
      "test Loss: 1.0387 Acc: 0.5016\n",
      "Epoch 14/14\n",
      "----------\n",
      "synthetic_train Loss: 1.0395 Acc: 0.4919\n",
      "test Loss: 1.0287 Acc: 0.4953\n",
      "Stopping early due to no improvement in validation loss.\n",
      "\n",
      "Training complete in 25m 50s\n",
      "Best test Loss: 1.026022\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "num_sims = 5\n",
    "\n",
    "train_percentage_dict = {\n",
    "    'NonDemented': 0.8,\n",
    "    'VeryMildDemented': 0.8,\n",
    "    'MildDemented': 0.8,\n",
    "    'ModerateDemented': 0.8,\n",
    "}\n",
    "\n",
    "synth_percentage_dict = {\n",
    "    'NonDemented': 0.0,\n",
    "    'VeryMildDemented': 0.0,\n",
    "    'MildDemented': 0.0,\n",
    "    'ModerateDemented': 0.0,\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'minimal': minimal_transforms,\n",
    "    'basic': basic_transforms,\n",
    "    'auto': auto_transforms\n",
    "}\n",
    "\n",
    "for active_transform in transforms.keys():\n",
    "    df_all_results = pd.DataFrame()\n",
    "    for n in range(num_sims):\n",
    "    \n",
    "        # make the synthetic training dataset\n",
    "        makeSyntheticTrain(\n",
    "            train_directory='../data/alzheimer_mri/train',\n",
    "            synthetic_train_directory='../data/alzheimer_mri/synthetic_train', \n",
    "            train_dict=train_percentage_dict, \n",
    "            synthetic_dict=synth_percentage_dict\n",
    "        )\n",
    "\n",
    "        # get and load datasets\n",
    "        data_dir = '../data/alzheimer_mri'\n",
    "        data_sets = ['synthetic_train','test']\n",
    "        image_datasets, dataloaders, dataset_sizes, class_names, device = get_data(\n",
    "            data_dir=data_dir, \n",
    "            data_sets=data_sets, \n",
    "            data_transforms=transforms.get(active_transform)\n",
    "        )\n",
    "\n",
    "        # instantiate model\n",
    "        model = ViT(\n",
    "            image_size = 224,\n",
    "            patch_size = 16,\n",
    "            num_classes = 4,\n",
    "            dim = 1024,\n",
    "            depth = 6,\n",
    "            heads = 16,\n",
    "            mlp_dim = 2048,\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1\n",
    "        )\n",
    "\n",
    "        # Set the size of each output sample to nn.Linear(num_ftrs, len(class_names))\n",
    "        model = model.to(device)\n",
    "\n",
    "        # train the model\n",
    "        df_results,_ = model = train_model(\n",
    "            model=model, \n",
    "            criterion = nn.CrossEntropyLoss(),\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001), \n",
    "            dataloaders=dataloaders,\n",
    "            dataset_sizes=dataset_sizes,\n",
    "            num_epochs=num_epochs\n",
    "        )\n",
    "\n",
    "        #df_results['train_percentage'] = train_percentage\n",
    "        #df_results['synth_percentage'] = synthetic_percentage\n",
    "        df_results['train_synth_ratio'] = '__'.join([k+str(v1)+'_'+str(v2) for k,v1,v2 in zip(train_percentage_dict.keys(),train_percentage_dict.values(),synth_percentage_dict.values())])\n",
    "        df_results['transform'] = active_transform\n",
    "        df_results['sim_num'] = n\n",
    "        df_results['category'] = df_results.apply(lambda row: row['transform']+'_'+'__'.join([k+str(v1)+'_'+str(v2) for k,v1,v2 in zip(train_percentage_dict.keys(),train_percentage_dict.values(),synth_percentage_dict.values())]), axis=1)\n",
    "        df_all_results = pd.concat([df_all_results, df_results],ignore_index=True)\n",
    "    df_all_results.to_csv(f'../results/results_vit_{active_transform}' + '__'.join([k+str(v1)+'_'+str(v2) for k,v1,v2 in zip(train_percentage_dict.keys(),train_percentage_dict.values(),synth_percentage_dict.values())]) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
