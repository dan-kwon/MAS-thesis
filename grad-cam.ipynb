{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/danielkwon/MAS-thesis/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model (for example, ResNet-50)\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook for the gradients of the target layer\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = None\n",
    "        # Forward pass through the layers\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name == self.target_layer:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs.append(x)\n",
    "        return outputs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to compute Grad-CAM\n",
    "class GradCam:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor(model, target_layer)\n",
    "\n",
    "    def __call__(self, input_tensor, target_class=None):\n",
    "        features, output = self.feature_extractor(input_tensor)\n",
    "\n",
    "        if target_class is None:\n",
    "            target_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        # Backpropagate to get the gradient of the target class\n",
    "        target = output[0, target_class]\n",
    "        target.backward()\n",
    "\n",
    "        # Get the gradients from the feature extractor\n",
    "        gradients = self.feature_extractor.gradients\n",
    "        # Get the feature maps from the layer\n",
    "        features = features[0]\n",
    "\n",
    "        # Global average pooling of the gradients\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "        # Multiply each channel in the feature map by the corresponding gradient\n",
    "        for i in range(features.shape[1]):\n",
    "            features[0, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "        # Average the weighted feature maps along the channels to get the heatmap\n",
    "        heatmap = torch.mean(features, dim=1).squeeze()\n",
    "\n",
    "        # Apply ReLU to the heatmap\n",
    "        heatmap = F.relu(heatmap)\n",
    "\n",
    "        # Normalize the heatmap\n",
    "        heatmap = heatmap - heatmap.min()\n",
    "        heatmap = heatmap / heatmap.max()\n",
    "\n",
    "        return heatmap.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "# Utility function to overlay the heatmap on the original image\n",
    "def overlay_heatmap(heatmap, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image and preprocess it\n",
    "img_path = '../data/alzheimer_mri/test/ModerateDemented/ModerateDemented_6.png'\n",
    "input_tensor = preprocess_image(img_path)\n",
    "\n",
    "# Create Grad-CAM object for the last convolutional layer (layer4 in ResNet-50)\n",
    "grad_cam = GradCam(model, target_layer='layer4')\n",
    "\n",
    "# Generate Grad-CAM heatmap for the target class (optional, if not provided, it uses the predicted class)\n",
    "heatmap = grad_cam(input_tensor)\n",
    "\n",
    "# Overlay the heatmap on the original image\n",
    "superimposed_img = overlay_heatmap(heatmap, img_path)\n",
    "\n",
    "# Display the image with the heatmap\n",
    "plt.imshow(superimposed_img[:, :, ::-1])  # Convert BGR to RGB for display\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
