{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.models.cnn import CNN\n",
    "from src.utility.generate_images import generateImages\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import shutil\n",
    "import torch.nn.functional as F\n",
    "from distutils.dir_util import copy_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Synthetic + Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_augmented_train(\n",
    "        train_dir,\n",
    "        test_dir,\n",
    "        synthetic_dir,\n",
    "        augmented_train_dir,\n",
    "        train_perc,\n",
    "        synthetic_perc\n",
    "    ):\n",
    "    # make directories if they don't already exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(synthetic_dir, exist_ok=True)\n",
    "    os.makedirs(augmented_train_dir, exist_ok=True)\n",
    "    \n",
    "    # loop through each class\n",
    "    for subfolder in [dir for dir in os.listdir(train_dir) if not dir.startswith('.')]:\n",
    "        os.makedirs(f\"{augmented_train_dir}/{subfolder}\", exist_ok=True)\n",
    "    \n",
    "        if subfolder == 'NonDemented':\n",
    "            from_directory = f\"{train_dir}/{subfolder}\"\n",
    "            to_directory = f\"{augmented_train_dir}/{subfolder}\"\n",
    "            copy_tree(from_directory, to_directory)    \n",
    "        else:\n",
    "            all_train_imgs = [f for f in os.listdir(f\"{train_dir}/{subfolder}\") if os.path.isfile(os.path.join(f\"{train_dir}/{subfolder}\", f))]\n",
    "            all_synthetic_imgs = [f for f in os.listdir(f\"{synthetic_dir}/{subfolder}\") if os.path.isfile(os.path.join(f\"{synthetic_dir}/{subfolder}\", f))]\n",
    "            chosen_train_imgs = random.sample(all_train_imgs, round(len(all_train_imgs)*train_perc))\n",
    "            chosen_synthetic_imgs = random.sample(all_synthetic_imgs, round(len(all_train_imgs)*synthetic_perc))\n",
    "            for img_name in chosen_train_imgs+chosen_synthetic_imgs:\n",
    "                \n",
    "                dst = f\"{augmented_train_dir}/{subfolder}/{img_name}\"\n",
    "\n",
    "                if 'generated' in img_name:\n",
    "                    src = f\"{synthetic_dir}/{subfolder}/{img_name}\"\n",
    "                else:\n",
    "                    src = f\"{train_dir}/{subfolder}/{img_name}\"\n",
    "                    \n",
    "                shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation to the image dataseet:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to a fixed size\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()           # Convert images to PyTorch tensors and scale to [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(augmented_train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Get one batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Number of images you want to display\n",
    "num_images = 4\n",
    "\n",
    "# Create a grid for the images\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Convert image tensor to numpy array and transpose the axes\n",
    "    # PyTorch tensors are in (C, H, W) format, and Matplotlib expects (H, W, C)\n",
    "    img = images[i].numpy().transpose(1, 2, 0)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('on')  # Turn off axis\n",
    "    axes[i].set_xlabel(f'Class: {class_names[labels[i].item()]}') # Set the label as x-axis label\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        train_dir,\n",
    "        test_dir,\n",
    "        synthetic_dir,\n",
    "        augmented_train_dir,\n",
    "        train_percs,\n",
    "        synthetic_percs,\n",
    "        transform\n",
    "):\n",
    "    for train_perc,synthetic_perc in zip(train_percs, synthetic_percs):\n",
    "        \n",
    "        # make synthetic + real mix\n",
    "        make_augmented_train(train_dir,test_dir,synthetic_dir,\n",
    "                            augmented_train_dir,train_perc,synthetic_perc)\n",
    "        \n",
    "        # load images\n",
    "        train_dataset = datasets.ImageFolder(augmented_train_dir, transform=transform)\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        \n",
    "        # create dataloader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        # Split the dataset into training and validation sets (80-20 split)\n",
    "        train_size = int(0.8 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_data, val_data= torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        # Create data loaders\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = CNN(\n",
    "            in_channels=1,\n",
    "            num_classes=4\n",
    "        )\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # train model\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 5  # Number of epochs to wait for improvement before stopping\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        num_epochs=10\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    val_corrects += torch.sum(preds == labels.data)\n",
    "                    all_preds.extend(preds.view(-1).cpu().numpy())\n",
    "                    all_labels.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            val_loss = val_loss / len(val_loader.dataset)\n",
    "            val_accuracy = val_corrects.double() / len(val_loader.dataset)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy}\")\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0  # Reset counter\n",
    "                torch.save(model.state_dict(), 'best_model.pth') # Save the model\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Early stopping check\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                break\n",
    "            \n",
    "        # store results in dataframe\n",
    "        dat = {\n",
    "            \"train_percentage\":[train_perc]*len(val_losses),\n",
    "            \"synthetic_percentage\":[synthetic_perc]*len(val_losses),\n",
    "            \"epoch\": range(len(val_losses)),\n",
    "            \"val_losses\": val_losses,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_accuracies\": [acc.item() for acc in val_accuracies]\n",
    "        }\n",
    "\n",
    "        result_df = pd.DataFrame(data=dat)\n",
    "\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.9374, Val Loss: 0.8642, Val Accuracy: 0.604982206405694\n",
      "Epoch 2/10, Train Loss: 0.7692, Val Loss: 0.8116, Val Accuracy: 0.6270462633451958\n",
      "Epoch 3/10, Train Loss: 0.6509, Val Loss: 0.6754, Val Accuracy: 0.7088967971530249\n",
      "Epoch 4/10, Train Loss: 0.5048, Val Loss: 0.5852, Val Accuracy: 0.7601423487544484\n",
      "Epoch 5/10, Train Loss: 0.3442, Val Loss: 0.5237, Val Accuracy: 0.7900355871886121\n",
      "Epoch 6/10, Train Loss: 0.2247, Val Loss: 0.4652, Val Accuracy: 0.8327402135231317\n",
      "Epoch 7/10, Train Loss: 0.1640, Val Loss: 0.4708, Val Accuracy: 0.8391459074733096\n",
      "Epoch 8/10, Train Loss: 0.1609, Val Loss: 0.4974, Val Accuracy: 0.8384341637010676\n",
      "Epoch 9/10, Train Loss: 0.0932, Val Loss: 0.6150, Val Accuracy: 0.8106761565836299\n",
      "Epoch 10/10, Train Loss: 0.0530, Val Loss: 0.5816, Val Accuracy: 0.8583629893238434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/22nrcfyj26bfczb8g410jks40000gn/T/ipykernel_48021/290902946.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all_results = pd.concat([df_all_results, df_sim_results],ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.0765, Val Loss: 1.0151, Val Accuracy: 0.5017397355601948\n",
      "Epoch 2/10, Train Loss: 0.8735, Val Loss: 0.8825, Val Accuracy: 0.5970772442588727\n",
      "Epoch 3/10, Train Loss: 0.7916, Val Loss: 0.7507, Val Accuracy: 0.6798886569241476\n",
      "Epoch 4/10, Train Loss: 0.6698, Val Loss: 0.7383, Val Accuracy: 0.6423103688239388\n",
      "Epoch 5/10, Train Loss: 0.5520, Val Loss: 0.6033, Val Accuracy: 0.7223382045929019\n",
      "Epoch 6/10, Train Loss: 0.4287, Val Loss: 0.5567, Val Accuracy: 0.7550452331245651\n",
      "Epoch 7/10, Train Loss: 0.3164, Val Loss: 0.4862, Val Accuracy: 0.81419624217119\n",
      "Epoch 8/10, Train Loss: 0.2118, Val Loss: 0.4794, Val Accuracy: 0.8204592901878914\n",
      "Epoch 9/10, Train Loss: 0.1419, Val Loss: 0.4628, Val Accuracy: 0.8329853862212944\n",
      "Epoch 10/10, Train Loss: 0.1052, Val Loss: 0.5061, Val Accuracy: 0.8608211551844119\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"data/alzheimer_mri/train\"\n",
    "test_dir = \"data/alzheimer_mri/test\"\n",
    "synthetic_dir = \"data/alzheimer_mri/synthetic\"\n",
    "dataset_dir = \"data/alzheimer_mri/augmented_train\"\n",
    "\n",
    "df_all_results = pd.DataFrame(columns = [\"sim_num\",\"train_percentage\",\"synthetic_percentage\",\"epoch\",\"val_losses\",\"train_losses\",\"val_accuracies\"])\n",
    "\n",
    "for n in range(2):\n",
    "    df_sim_results = train_model(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir, \n",
    "        synthetic_dir=synthetic_dir,\n",
    "        augmented_train_dir=dataset_dir,\n",
    "        train_percs=[0.9],\n",
    "        synthetic_percs=[0.1],\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    df_sim_results[\"sim_num\"] = n\n",
    "\n",
    "    df_all_results = pd.concat([df_all_results, df_sim_results],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_num</th>\n",
       "      <th>train_percentage</th>\n",
       "      <th>synthetic_percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_losses</th>\n",
       "      <th>train_losses</th>\n",
       "      <th>val_accuracies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864224</td>\n",
       "      <td>0.937417</td>\n",
       "      <td>0.604982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811566</td>\n",
       "      <td>0.769159</td>\n",
       "      <td>0.627046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675359</td>\n",
       "      <td>0.650910</td>\n",
       "      <td>0.708897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.585174</td>\n",
       "      <td>0.504782</td>\n",
       "      <td>0.760142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.523734</td>\n",
       "      <td>0.344219</td>\n",
       "      <td>0.790036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.465219</td>\n",
       "      <td>0.224698</td>\n",
       "      <td>0.832740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.470845</td>\n",
       "      <td>0.163978</td>\n",
       "      <td>0.839146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.497437</td>\n",
       "      <td>0.160866</td>\n",
       "      <td>0.838434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>0.093155</td>\n",
       "      <td>0.810676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.581578</td>\n",
       "      <td>0.052978</td>\n",
       "      <td>0.858363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.015148</td>\n",
       "      <td>1.076497</td>\n",
       "      <td>0.501740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882518</td>\n",
       "      <td>0.873491</td>\n",
       "      <td>0.597077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.791567</td>\n",
       "      <td>0.679889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.669793</td>\n",
       "      <td>0.642310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.603332</td>\n",
       "      <td>0.552001</td>\n",
       "      <td>0.722338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.428652</td>\n",
       "      <td>0.755045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.486191</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.479358</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.820459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.462815</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>0.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.506148</td>\n",
       "      <td>0.105186</td>\n",
       "      <td>0.860821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sim_num  train_percentage  synthetic_percentage epoch  val_losses  \\\n",
       "0        0               0.9                   0.1     0    0.864224   \n",
       "1        0               0.9                   0.1     1    0.811566   \n",
       "2        0               0.9                   0.1     2    0.675359   \n",
       "3        0               0.9                   0.1     3    0.585174   \n",
       "4        0               0.9                   0.1     4    0.523734   \n",
       "5        0               0.9                   0.1     5    0.465219   \n",
       "6        0               0.9                   0.1     6    0.470845   \n",
       "7        0               0.9                   0.1     7    0.497437   \n",
       "8        0               0.9                   0.1     8    0.615037   \n",
       "9        0               0.9                   0.1     9    0.581578   \n",
       "10       1               0.9                   0.1     0    1.015148   \n",
       "11       1               0.9                   0.1     1    0.882518   \n",
       "12       1               0.9                   0.1     2    0.750734   \n",
       "13       1               0.9                   0.1     3    0.738283   \n",
       "14       1               0.9                   0.1     4    0.603332   \n",
       "15       1               0.9                   0.1     5    0.556710   \n",
       "16       1               0.9                   0.1     6    0.486191   \n",
       "17       1               0.9                   0.1     7    0.479358   \n",
       "18       1               0.9                   0.1     8    0.462815   \n",
       "19       1               0.9                   0.1     9    0.506148   \n",
       "\n",
       "    train_losses  val_accuracies  \n",
       "0       0.937417        0.604982  \n",
       "1       0.769159        0.627046  \n",
       "2       0.650910        0.708897  \n",
       "3       0.504782        0.760142  \n",
       "4       0.344219        0.790036  \n",
       "5       0.224698        0.832740  \n",
       "6       0.163978        0.839146  \n",
       "7       0.160866        0.838434  \n",
       "8       0.093155        0.810676  \n",
       "9       0.052978        0.858363  \n",
       "10      1.076497        0.501740  \n",
       "11      0.873491        0.597077  \n",
       "12      0.791567        0.679889  \n",
       "13      0.669793        0.642310  \n",
       "14      0.552001        0.722338  \n",
       "15      0.428652        0.755045  \n",
       "16      0.316396        0.814196  \n",
       "17      0.211838        0.820459  \n",
       "18      0.141898        0.832985  \n",
       "19      0.105186        0.860821  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#0.2543\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title(\"Training and Validation Losses per Epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title(\"Validation Accuracy per Epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth')) # This line uses .load() to read a .pth file and load the network weights on to the architecture.\n",
    "model.eval() # enabling the eval mode to test with new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,1,128,128)\n",
    "inputs = inputs.to(device) # You can move your input to gpu, torch defaults to cpu\n",
    "\n",
    "# Run forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(inputs)\n",
    "\n",
    "_, pred = torch.max(output, 1)\n",
    "\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Storage for predictions and actual labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluation loop\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to arrays for metric calculation\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calculate metrics for each class\n",
    "for class_index in range(4):  # Replace num_classes with the actual number of classes\n",
    "    class_preds = (all_preds == class_index)\n",
    "    class_labels = (all_labels == class_index)\n",
    "    accuracy = accuracy_score(class_labels, class_preds)\n",
    "    precision = precision_score(class_labels, class_preds, zero_division=0)\n",
    "    recall = recall_score(class_labels, class_preds, zero_division=0)\n",
    "\n",
    "    class_name = class_names[class_index]\n",
    "\n",
    "    print(f\"Class name {class_name}({class_index}) - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and preprocess it\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(r\"data/alzheimer_mri/train/ModerateDemented/ModerateDemented_0.png\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "#def pred_class(image_tensor):\n",
    "img_im = image_tensor.unsqueeze(0).to(device)\n",
    "#uinput = Variable(img_im)\n",
    "#uinput = uinput.to(device)\n",
    "out = model(uinput)\n",
    "\n",
    "index = out.data.cpu().numpy().argmax()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
